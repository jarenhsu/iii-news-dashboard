import streamlit as st
import pandas as pd
from urllib.parse import urlparse

# 1. é é¢é¢¨æ ¼è¨­å®š (æ·±è‰²å¤§è³é¢¨æ ¼)
st.set_page_config(page_title="è³‡ç­–æœƒæ–°èè§€æ¸¬ç«™", layout="centered")

st.markdown("""
    <style>
    .stApp { background-color: #0e0e0e; color: #f0f0f0; }
    .news-card {
        background-color: #1a1a1a; padding: 30px; border-radius: 15px;
        border: 1px solid #333; margin-bottom: 25px; 
    }
    .main-title { text-align: center; color: #fff; font-weight: 900; font-size: 2.2em; margin-top: 20px; }
    .sub-title { text-align: center; color: #d4af37; font-size: 1em; margin-bottom: 40px; letter-spacing: 2px; }
    .rank-text { color: #d4af37; font-weight: 900; font-size: 1.8em; margin-bottom: 10px; }
    .news-title { font-size: 1.5em; font-weight: 700; color: #fff; margin: 10px 0; line-height: 1.4; }
    .source-container { margin-top: 20px; padding-top: 15px; border-top: 1px dashed #444; }
    .source-btn {
        display: inline-block; background-color: #2c2c2c; color: #d4af37 !important;
        padding: 6px 14px; border-radius: 20px; font-size: 0.85em;
        margin: 5px; border: 1px solid #d4af37; text-decoration: none;
    }
    .source-btn:hover { background-color: #d4af37; color: #000 !important; }
    </style>
    """, unsafe_allow_html=True)

# åª’é«”åç¨±è½‰æ›
def get_media_label(url):
    if not isinstance(url, str) or "google" in url: return "åª’é«”å ±å°"
    mapping = {
        "yahoo": "Yahooæ–°è", "udn": "è¯åˆæ–°è", "ltn": "è‡ªç”±æ™‚å ±", "chinatimes": "ä¸­æ™‚",
        "ettoday": "ETtoday", "storm": "é¢¨å‚³åª’", "cna": "ä¸­å¤®ç¤¾", "setn": "ä¸‰ç«‹æ–°è",
        "tvbs": "TVBS", "find.org.tw": "FINDä¸­å¿ƒ", "iii.org.tw": "è³‡ç­–æœƒå®˜ç¶²"
    }
    domain = urlparse(url).netloc.lower()
    for key, name in mapping.items():
        if key in domain: return name
    return "ç›¸é—œå ±å°"

st.markdown("<div class='main-title'>ğŸ“¡ è³‡ç­–æœƒè¼¿æƒ…ç†±åº¦è§€æ¸¬ç«™</div>", unsafe_allow_html=True)
st.markdown("<div class='sub-title'>WEEKLY TRENDING REPORT</div>", unsafe_allow_html=True)

# 2. æ•¸æ“šè™•ç†
SHEET_ID = "1cwFO20QP4EZrl5PYVOjVgevJS2D1VzCUazb9x0fHEoI"
csv_url = f"https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv"

try:
    # ğŸ’¡ é—œéµä¿®æ­£ï¼šè·³éæå£è¡Œä¸¦ä½¿ç”¨ Python å¼•æ“
    df = pd.read_csv(csv_url, on_bad_lines='skip', engine='python')
    
    # ğŸ’¡ å¼·åˆ¶é–å®šï¼šä¸è«–åç¨±ï¼Œç›´æ¥è®€å–ç¬¬ 3 æ¬„ (æ¨™é¡Œ) å’Œç¬¬ 4 æ¬„ (é€£çµ)
    df['title'] = df.iloc[:, 2].fillna("æœªçŸ¥æ¨™é¡Œ").astype(str).str.replace(r'\n', '', regex=True).str.strip()
    df['link'] = df.iloc[:, 3].fillna("").astype(str).str.strip()

    # æ’é™¤ç¬¬ä¸€åˆ—æ˜¯æ¨™é¡Œæ–‡å­—çš„æƒ…æ³
    df = df[~df['title'].str.contains("æ–°èæ¨™é¡Œ")]

    # èšåˆè³‡æ–™
    grouped = df.groupby('title')['link'].apply(list).reset_index()
    grouped['count'] = grouped['link'].apply(len)
    grouped = grouped.sort_values(by='count', ascending=False).head(15)

    if grouped.empty:
        st.info("ğŸ’¡ è©¦ç®—è¡¨é€£ç·šæˆåŠŸï¼Œä½†ç›®å‰æ²’æœ‰æœ‰æ•ˆçš„è¼¿æƒ…è³‡æ–™ã€‚")
    else:
        for i, (_, row) in enumerate(grouped.iterrows()):
            title = row['title']
            links = row['link']
            count = row['count']
            
            medal = "ğŸ¥‡ CHAMPION" if i == 0 else "ğŸ¥ˆ SILVER" if i == 1 else "ğŸ¥‰ BRONZE" if i == 2 else f"TOP {i+1}"
            links_html = "".join([f'<a class="source-btn" href="{u}" target="_blank">ğŸŒ {get_media_label(u)}</a>' for u in links if u and 'http' in u])
            
            st.markdown(f"""
                <div class="news-card">
                    <div class="rank-text">{medal}</div>
                    <div class="news-title">{title}</div>
                    <div style="color: #d4af37; font-weight: bold; margin-bottom: 10px;">ğŸ”¥ ç†±åº¦ï¼š{count} æ¬¡å ±å°</div>
                    <div class="source-container">
                        <div style="color: #888; font-size: 0.8em; margin-bottom: 10px;">ğŸ”— åª’é«”ä¾†æºï¼š</div>
                        {links_html}
                    </div>
                </div>
                """, unsafe_allow_html=True)

except Exception as e:
    st.error(f"âš ï¸ è³‡æ–™è§£æä¸­ï¼Œè«‹ç¢ºä¿è©¦ç®—è¡¨å·²ç™¼ä½ˆã€‚")
