import streamlit as st
import pandas as pd
from urllib.parse import urlparse

# 1. é é¢é¢¨æ ¼è¨­å®š
st.set_page_config(page_title="è³‡ç­–æœƒæ–°èè§€æ¸¬ç«™", layout="centered")

st.markdown("""
    <style>
    .stApp { background-color: #0e0e0e; color: #f0f0f0; }
    .news-card {
        background-color: #1a1a1a; padding: 30px; border-radius: 15px;
        border: 1px solid #333; margin-bottom: 25px; 
    }
    .main-title { text-align: center; color: #fff; font-weight: 900; font-size: 2.2em; margin-top: 20px; }
    .sub-title { text-align: center; color: #d4af37; font-size: 1em; margin-bottom: 40px; letter-spacing: 2px; }
    .rank-text { color: #d4af37; font-weight: 900; font-size: 1.8em; margin-bottom: 10px; }
    .news-title { font-size: 1.5em; font-weight: 700; color: #fff; margin: 10px 0; line-height: 1.4; }
    .source-container { margin-top: 20px; padding-top: 15px; border-top: 1px dashed #444; }
    .source-btn {
        display: inline-block; background-color: #2c2c2c; color: #d4af37 !important;
        padding: 6px 14px; border-radius: 20px; font-size: 0.85em;
        margin: 5px; border: 1px solid #d4af37; text-decoration: none;
    }
    .source-btn:hover { background-color: #d4af37; color: #000 !important; }
    </style>
    """, unsafe_allow_html=True)

# åª’é«”åç¨±è½‰æ›åŠ å¼·ç‰ˆ
def get_media_label(url):
    if not isinstance(url, str) or "google" in url: return "åª’é«”å ±å°"
    mapping = {
        "yahoo": "Yahooæ–°è", "udn": "è¯åˆæ–°è", "ltn": "è‡ªç”±æ™‚å ±", "chinatimes": "ä¸­æ™‚",
        "ettoday": "ETtoday", "storm": "é¢¨å‚³åª’", "cna": "ä¸­å¤®ç¤¾", "setn": "ä¸‰ç«‹æ–°è",
        "tvbs": "TVBS", "find.org.tw": "FINDä¸­å¿ƒ", "iii.org.tw": "è³‡ç­–æœƒå®˜ç¶²"
    }
    domain = urlparse(url).netloc.lower()
    for key, name in mapping.items():
        if key in domain: return name
    return "ç›¸é—œå ±å°"

st.markdown("<div class='main-title'>ğŸ“¡ è³‡ç­–æœƒè¼¿æƒ…ç†±åº¦è§€æ¸¬ç«™</div>", unsafe_allow_html=True)
st.markdown("<div class='sub-title'>WEEKLY TRENDING REPORT</div>", unsafe_allow_html=True)

# 2. æ•¸æ“šè™•ç†
SHEET_ID = "1cwFO20QP4EZrl5PYVOjVgevJS2D1VzCUazb9x0fHEoI"
csv_url = f"https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv"

try:
    # ğŸ’¡ ä¿®æ­£é—œéµï¼šå¼·åˆ¶è·³ééŒ¯èª¤è¡Œï¼Œä¸¦æŒ‡å®šæ¬„ä½ç´¢å¼•
    df = pd.read_csv(csv_url, on_bad_lines='skip', engine='python')
    
    # é–å®šä½ç½®ï¼šç¬¬3æ¬„(ç´¢å¼•2)æ¨™é¡Œï¼Œç¬¬4æ¬„(ç´¢å¼•3)é€£çµ
    # æ¸…æ´—æ‰æ¨™é¡Œå…§çš„æ›è¡Œç¬¦è™Ÿ \n ä»¥é˜²åˆ†çµ„å¤±æ•—
    df['clean_title'] = df.iloc[:, 2].astype(str).str.replace(r'\n', '', regex=True).str.strip()
    df['clean_link'] = df.iloc[:, 3].astype(str).str.strip()

    # éæ¿¾æ‰ã€Œæ–°èæ¨™é¡Œã€é€™ç¨®æ¨™é ­æ–‡å­—æˆ–ç©ºæ¨™é¡Œ
    df = df[df['clean_title'] != 'æ–°èæ¨™é¡Œ']
    df = df[df['clean_title'] != 'nan']

    # èšåˆè³‡æ–™
    grouped = df.groupby('clean_title')['clean_link'].apply(list).reset_index()
    grouped['count'] = grouped['clean_link'].apply(len)
    # ä¾ç†±åº¦æ’åºå‰ 15 å
    grouped = grouped.sort_values(by='count', ascending=False).head(15)

    for i, (_, row) in enumerate(grouped.iterrows()):
        title = row['clean_title']
        links = row['clean_link']
        count = row['count']
        
        # çç‰Œæ¨™ç±¤
        medal = "ğŸ¥‡ CHAMPION" if i == 0 else "ğŸ¥ˆ SILVER" if i == 1 else "ğŸ¥‰ BRONZE" if i == 2 else f"TOP {i+1}"
        
        # ç”Ÿæˆé€£çµæŒ‰éˆ•
        links_html = "".join([f'<a class="source-btn" href="{u}" target="_blank">ğŸŒ {get_media_label(u)}</a>' for u in links if u and 'http' in str(u)])
        
        # é¡¯ç¤ºå¡ç‰‡
        st.markdown(f"""
            <div class="news-card">
                <div class="rank-text">{medal}</div>
                <div class="news-title">{title}</div>
                <div style="color: #d4af37; font-weight: bold; margin-bottom: 10px;">ğŸ”¥ ç†±åº¦ï¼š{count} æ¬¡å ±å°</div>
                <div class="source-container">
                    <div style="color: #888; font-size: 0.8em; margin-bottom: 10px;">ğŸ”— åª’é«”ä¾†æºï¼š</div>
                    {links_html}
                </div>
            </div>
            """, unsafe_allow_html=True)

except Exception as e:
    st.error(f"è³‡æ–™æ ¡æº–ä¸­ï¼Œè«‹ç¨å€™ã€‚")
